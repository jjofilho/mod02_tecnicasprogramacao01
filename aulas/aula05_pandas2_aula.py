# -*- coding: utf-8 -*-
"""aula05_pandas2_aula.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fmpSqb3dWS8AYHmGWDmi6imngpB19xc2

# Pandas

### DataFrame

Agora que conhecemos as séries, vamos partir pro objeto do Pandas que mais utilizaremos: o **DataFrame**

Como veremos a seguir, o DataFrame é uma estrutura que se assemalha a uma **tabela**.

Estruturalmente, o DataFrame nada mais é que um **conjunto de Series**, uma para cada coluna (e, claro, com mesmo índice, que irão indexar as linhas).
  
Veremos depois como **ler um dataframe a partir de um arquivo** (que é provavelmente a forma mais comum)

Há muitas formas de construir um DataFrame do zero. Todas elas fazem uso da função **pd.DataFrame()**, como veremos a seguir.

Se quisermos especificar os índices de linha, o nome das colunas, e os dados, podemos passá-los separadamente:
"""

import pandas as pd
import numpy as np

# gerando uma matriz (5, 3) de numeros inteiros aleatórios entre -100 e 100
# use a seed 42

np.random.seed(42)

m = np.random.randint(-100, 100, (5, 3))

m

pd.DataFrame(m)

df_nome_linhas = pd.DataFrame(m, index = ['obs1', 'obs2','obs3', 'obs4', 'obs5'],
                             columns=['variável_1', 'variáve_ 2','variável_3'] )
df_nome_linhas

"""A partir de um arquivo"""

df = pd.read_table("../dados/dados_religiao_income.txt",header=0, sep=' ')

df.head()

"""## Exercício:

 1. Utilizando o conjunto de dados 'dados_artificiais.txt':
    1. Leia o dataset
    2. Adicione a coluna de IMC > IMC = peso / altura**2
    3. Filtre e reserve uma nova variável para todos os IMC's que são considerados:
       1. Sobrepeso >
       2. < Baixo peso

| IMC             | Categoria           |   |
|-----------------|---------------------|---|
| abaixo de 16,00 | Baixo peso Grau III |   |
| 16,00 a 16,99   | Baixo peso Grau II  |   |
| 17,00 a 18.49   | Baixo peso Grau I   |   |
| 18,50 a 24,99   | Peso ideal          |   |
| 25,00 a 29,99   | Sobrepeso           |   |
| 30,00 a 34,99   | Obesidade Grau I    |   |
| 35,00 a 39,99   | Obesidade Grau II   |   |
| 40,0 e acima    | Obesidade Grau III  |   |

"""

exe = pd.read_table('../dados/dados_artificiais copy.txt', sep='  ' ,engine='python')
exe.head(2)

#Vitor Galves
imc = exe['peso'] / (exe['altura']**2)
exe['imc'] = imc
exe.head(2)

# Flanderson
exe['IMC'] = exe['peso'] / (exe['altura'] ** 2)

exe['imc'] = exe.peso/(exe.altura ** 2)
exe.head(2)

sobrepeso = exe[exe['imc']>=30]
sobrepeso

"""O potencial do pandas é melhor aproveitado quando usamos o conceito de "tidy data" para organizarmos nossos dados.

Nos dados acima, eles estão pivoteados por segmentos de rendimento.

Vamos então tentar ajustar isso.

Para listarmos as colunas o DataFrame possui um atributo .columns que imprime esta informação em formato de lista.
"""

df.columns

# Veja que podemos trabalhar como listas normalmente
value_cols = [col for col in df.columns if col != 'religion']
value_cols

"""## Funções Pandas
  
### melt  
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html
"""

# Podemos utilizar a função do Pandas .melt para alterar a visão do dataframe
new_df = pd.melt(
    df,
    id_vars=["religion"],
    value_vars=value_cols,
    var_name="income",
    value_name="freq",
)

new_df

"""### pivot_table"""

# Podemos voltar para o formato anterior, que facilita apresentações para o negócio.
# Usamos o método pivot.
new_df.pivot(index='religion', columns='income',values='freq' )

new_df.pivot_table(index='religion', columns='income', values='freq', aggfunc='mean')

"""### Concat  
  
É possível realizar a concatenação de dois ou mais dataframes por meio do método "concat".
"""

# Criação de DataFrames por meio de dicionários
df1 = pd.DataFrame({'nome':['eu', 'tu', 'ele/ela'],
                    'val': [1,1,1]})
# Criação de DataFrames por meio de listas
lista_valores = [
    ['nós', 2],
    ['vós',2],
    ['eles/elas',2]
]
df2 = pd.DataFrame(lista_valores, columns=['nome', 'val'])

df1

df2

df1.columns.to_list() == df2.columns.to_list()

# Repare que por padrão o pandas já realiza o empilhamento dos dois dataframes, mas os índices estão confusos
pd.concat([df1, df2]).reset_index(drop=True)

# Utilizamos o método .copy() para fazermos uma cópia do dataframe
new_df = df2.copy()
# O atributo .index do dataframe chama os índices
new_df.index=[4,5,6]
new_df

pd.concat([df1, new_df], axis=0)

"""Caso se queira colocar um do lado do outro, invés de em cima, usamos o parâmetro "axis"."""

# Agora ao passarmos o axis=1 ele entende que desejamos realizar uma concatenação "lateral" - também conhecido como merge
pd.concat([df1, new_df], axis=1)

"""### Rename
  
O rename é utilizado para renomear labels do dataframe
"""

df1

# Para renomearmos as colunas de um dataframe utilizamos um dicionário tendo como chave
# o valor antigo e valor o novo
# inplace = True sem ele a variável não muda
df1.rename(columns={'nome': 'nome_alterado'})

df1.columns

df1.columns = ['nome_alterado', 'valor']
df1

"""## Exploração de dados: Estatísticas"""

df = pd.read_table('../dados/dados_parciais.txt', sep=';', decimal=',')

"""### Head"""

# O head é utilizado para observarmos o início de um dataframe
df.head(3)

"""### Tail"""

# O tail é utilizado para observarmos o final de um dataframe
df.tail(3)

"""### Describe"""

# Podemos sumarizar algumas estatísticas de várias colunas de uma única vez.
df.describe()

stats = df.describe()
type(stats)

stats

stats['pop_urbana']

"""### Outras estatísticas"""

# calculando uma estatística por vez
df[["superficie", "pop_urbana", "pop_rural", "total"]].mean()

df[["superficie", "pop_urbana", "pop_rural", "total"]].median()

df[["superficie", "pop_urbana", "pop_rural", "total"]].quantile([.25, .75])

df[["superficie", "pop_urbana", "pop_rural", "total"]].min()

df.columns

new_df = df[['regiao','superficie', 'pop_urbana', 'pop_rural', 'total']]

df.head()

df.groupby(['regiao', 'uf']).agg({'superficie':'mean', 'pop_urbana':'std'})



regioes_agrupadas.head()

"""## Exercicios
1. Resete o INDEX do dataframe transformado ele em Coluna exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],
        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],
        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}
2. Crie um filtro para Kevin e Laura
3. Crie um filtro para todos que tiveram um numero de tentativa(attempts) mair que 2
4. Preencha os np.nan com 0
"""

exam_data = pd.DataFrame(
    {
        "name": [
            "Anastasia",
            "Dima",
            "Katherine",
            "James",
            "Emily",
            "Michael",
            "Matthew",
            "Laura",
            "Kevin",
            "Jonas",
        ],
        "score": [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],
        "attempts": [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        "qualify": ["yes", "no", "yes", "no", "no", "yes", "yes", "no", "no", "yes"],
    }
)

exam_data.head()

#2 Luiza
exam_data[exam_data['name'].isin(['Kevin','Laura'])]

# Outra forma
exam_data[(exam_data['name']=='Kevin')| (exam_data['name']=='Laura')]

#3
exam_data[exam_data.attempts>2]

#4
# exam_data[exam_data['score'].isna()]

exam_data.fillna(0, inplace=True)

exam_data

"""### Importando novo Dataframe"""

# importando o dataframe de municípios



"""### Colunas
  
Podemos acessar os dados de uma colunas de três métodos
"""

df_muni = pd.read_table('../dados/populacao_brasileira_por_municipio.txt', sep=';', thousands='.')

df_muni.head(10)

"""## Colunas"""

df_muni.UF

type(df_muni.UF)

type(df_muni.UF.values)

df_muni['UF']

type(df_muni[['UF']])

"""### Query
  
O método query permite realizar filtros dentro do nosso dataframe semelhante ao utilizado na linguagem SQL na clausula where
"""

df_muni.head(1)

# quero saber quais cidades tem população urbana > 500000
df_muni.query(' `POPULAÇÃO ESTIMADA` > 1000 ')

# podemos usar uma variável
limite = 5000

df_muni.query(" `POPULAÇÃO ESTIMADA` < @limite")

"""### .loc e .iloc"""

df_muni.head(3)

# .loc usado para pesquisar índices e colunas explicitamente

# quero a população urbana da segunda linha do dataset
df_muni.loc[1, 'NOME DO MUNICÍPIO']

# qual estado corresponde à segunda linha do dataset
df_muni.loc[1, :]

# posso usar lógicas para filtrar o dataset

# quais estados pertencem à região NE?
df_muni.loc[df_muni["UF"]=='BA', 'COD. UF']

# quais estados pertencem à região NE e N?
df_muni.loc[(df_muni['UF']=='BA') | ( df_muni['NOME DO MUNICÍPIO']=='Feira de Santana')]

df_muni.head(10)

# iloc faz a referência aos índices e colunas de forma implícita
df_muni.iloc[2,2]

"""## Seleção de colunas pelo tipo:"""



"""## Exercício:
1. Seleção de municípios por tamanho da população usando loc - 500k
2. Seleção de linhas específicas usando iloc - (10, 20)
3. Utilizar query para filtrar municípios com população entre 10.000 e 50.000 habitantes
4. Calcular a população total do estado de Rondônia usando operações matemáticas no Pandas.
5. Criação de uma nova coluna usando operações matemáticas e loc - População média
"""

df_muni.rename(
    columns={
        "UF": "uf",
        "COD. UF": "cod_uf",
        "COD. MUNIC": "cod_muni",
        "NOME DO MUNICÍPIO": "nome_municipio",
        "POPULAÇÃO ESTIMADA": "pop_estimada",
    },
    inplace=True,
)
df_muni.head()

#1
df_muni.loc[df_muni['pop_estimada'] > 500000]

#1
df_muni.loc[lambda df_muni: df_muni['pop_estimada']> 500000]

#2
df_muni.iloc[[10,20]]

#3
df_muni.query(' 10000 <= pop_estimada <= 50000 ')

#4
df_muni[['uf', 'pop_estimada']].groupby('uf').agg('sum').loc['RO']

df_muni.groupby('uf').agg({'pop_estimada':'sum'}).loc['RO']

df_muni

#5
media_por_estado = df_muni.groupby('uf')['pop_estimada'].mean()

media_por_estado

"""### Operações matemáticas"""

df.head()

# quero saber a razão entre as população urbana e a população rural
df['razao_urbana_rural'] = df['pop_urbana']/df['pop_rural']
df.head()

# se eu chamar uma coluna inexiste em modo de leitura
# df['frac_urbana']

# calcular a fração da população urbana sobre a geral
df['frac_urbana'] = df['pop_urbana']/df['total']
df.head()

# iterar por cada linha e atribuir 1 se frac_urbana > 0.7 e 0 caso contrário
for uf in df.index:
    if df.loc[uf, 'frac_urbana']>0.7:
        df.loc[uf, 'indicador'] =1
    else:
        df.loc[uf, 'indicador'] =0

df.head()

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# for uf in df.index:
#     if df.loc[uf, 'frac_urbana']>0.7:
#         df.loc[uf, 'indicador'] =1
#     else:
#         df.loc[uf, 'indicador'] =0
#

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# df['indicador'] =df['frac_urbana'].apply(lambda x: 1 if x > 0.7 else 0)

ponto_cardeal = {
    'Nordeste': 'NE',
    'Centro-Oeste': 'CO',
    'Sul': 'S',
    'Sudeste': 'SE',
    'Norte':'N'
}

# podemos fazer transformações com dicionários
df['regiao_pc'] = df['regiao'].map(ponto_cardeal)

df.head(10)

df.head()

# usando o apply em múltiplas colunas
def soma_quadrados(row):
    soma = (row["pop_urbana"] ** 2 + row["pop_rural"] ** 2) / (row["total"] ** 2)
    return soma

df['indicador2'] = df.apply(soma_quadrados, axis=1)

df.head()

"""### Merge (join)

Outra tarefa muito comum quando estamos trabalhando com bases de dados é o **cruzamento**

Para fazer isso, utilizamos o método **.merge()**, cujos modos de cruzamento são:

<img src="https://community.qlik.com/legacyfs/online/87693_all-joins.png" width=450 style="background-color:white">
"""

lista_on_left = [ 1,2,3,4,5,6,7,8,9,10]
lista_on_right = [1,3,5,7,9, 15, 20 , 55]

dict_left= { 'coluna_on':lista_on_left, 'valores_esquerda': lista_on_left}
dict_right = {'coluna_on': lista_on_right, 'valores_direita': lista_on_right}

df_left = pd.DataFrame(dict_left)
df_left

df_right = pd.DataFrame(dict_right)
df_right

df_left.merge(df_right,on='coluna_on', how="inner")

df = df.reset_index()
df.head()

df_novo = pd.merge(df_muni, df, on='uf', how='left ')

df_novo.head()

# quero a média e o desvio padrão da população estimada por região

df_novo.groupby('regiao').agg({'pop_estimada':['mean', 'std', 'median']})

"""**Bora praticar!**
  
1) Utilizando o DataFrame importado anteriormente (alunos3.csv) calcule a média das provas em uma nova coluna chamada (Media_provas)
"""





"""2) Quem foram os alunos que obtiveram a maior e a menor média"""









"""3) Agora una este dataframe com o cadastro_alunos.xlsx"""





"""4) Qual a média entre as Media_provas dentro do público feminino? e masculino?"""



"""5) Qual a média de idade das pessoas que obtiveram Media_provas maior ou igual a 7?"""









"""6) Qual das cidades possui o maior média de Media_provas? E qual é este valor?"""